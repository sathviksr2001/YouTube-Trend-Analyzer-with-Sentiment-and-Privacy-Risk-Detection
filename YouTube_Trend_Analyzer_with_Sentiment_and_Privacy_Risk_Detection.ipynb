{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwC3Holnqv1DoIk0s+Ycl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathviksr2001/YouTube-Trend-Analyzer-with-Sentiment-and-Privacy-Risk-Detection/blob/main/YouTube_Trend_Analyzer_with_Sentiment_and_Privacy_Risk_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install --quiet gradio google-api-python-client textblob matplotlib\n",
        "\n",
        "import gradio as gr\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import io\n",
        "import base64\n",
        "import re"
      ],
      "metadata": {
        "id": "4sCP4n2DemJi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube API setup\n",
        "api_key = \"YOUR API KEY HERE\"\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n"
      ],
      "metadata": {
        "id": "esvNM5ghSMX9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch trending videos from YouTube API\n",
        "def fetch_trending_videos(region='IN', max_results=10):\n",
        "    request = youtube.videos().list(\n",
        "        part='snippet,statistics',\n",
        "        chart='mostPopular',\n",
        "        regionCode=region,\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response = request.execute()\n",
        "    return response"
      ],
      "metadata": {
        "id": "36NL0cW7SSX9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Privacy Leakage Detection Function\n",
        "def detect_privacy_leakage(row):\n",
        "    description = row['description'].lower()\n",
        "    title = row['title'].lower()\n",
        "    tags = row['tags'].lower()\n",
        "    score = 0\n",
        "\n",
        "    if re.search(r\"\\b\\d{10}\\b\", description):\n",
        "        score += 2\n",
        "    if re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", description):\n",
        "        score += 2\n",
        "    if any(word in description for word in [\"address\", \"home\", \"location\", \"live at\"]):\n",
        "        score += 1\n",
        "    if any(word in tags for word in [\"personal\", \"private\", \"diary\", \"secrets\"]):\n",
        "        score += 1\n",
        "\n",
        "    if score >= 3:\n",
        "        return \"High Risk\"\n",
        "    elif score == 2:\n",
        "        return \"Medium Risk\"\n",
        "    else:\n",
        "        return \"Low Risk\""
      ],
      "metadata": {
        "id": "mGrgcXBOSVzu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and engineer features\n",
        "def parse_response(response):\n",
        "    data = []\n",
        "    for item in response['items']:\n",
        "        snippet = item['snippet']\n",
        "        stats = item['statistics']\n",
        "        published_at = snippet['publishedAt']\n",
        "        published_dt = pd.to_datetime(published_at)\n",
        "\n",
        "        title = snippet['title']\n",
        "        description = snippet.get('description', '')\n",
        "        tags = snippet.get('tags', [])\n",
        "        title_length = len(title)\n",
        "        description_length = len(description)\n",
        "        tags_count = len(tags)\n",
        "        published_hour = published_dt.hour\n",
        "        published_day = published_dt.weekday()\n",
        "\n",
        "        title_sentiment = TextBlob(title).sentiment.polarity\n",
        "        desc_sentiment = TextBlob(description).sentiment.polarity\n",
        "        title_sentiment_label = 'Positive' if title_sentiment > 0 else ('Negative' if title_sentiment < 0 else 'Neutral')\n",
        "        desc_sentiment_label = 'Positive' if desc_sentiment > 0 else ('Negative' if desc_sentiment < 0 else 'Neutral')\n",
        "\n",
        "        current_views = int(stats.get('viewCount', 0))\n",
        "        prev_day_views = int(current_views * 0.8)  # Simulate 20% growth\n",
        "        momentum = current_views - prev_day_views\n",
        "\n",
        "        data.append({\n",
        "            'title': title,\n",
        "            'channel': snippet['channelTitle'],\n",
        "            'published at': published_at,\n",
        "            'views': current_views,\n",
        "            'likes': int(stats.get('likeCount', 0)),\n",
        "            'comments': int(stats.get('commentCount', 0)),\n",
        "            'title length': title_length,\n",
        "            'description': description,\n",
        "            'tags': \", \".join(tags),\n",
        "            'description length': description_length,\n",
        "            'tags count': tags_count,\n",
        "            'published hour': published_hour,\n",
        "            'published day': published_day,\n",
        "            'title sentiment': title_sentiment_label,\n",
        "            'description sentiment': desc_sentiment_label,\n",
        "            'momentum': momentum\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['privacy risk'] = df.apply(detect_privacy_leakage, axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "i0rvLaQOSgBN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create matplotlib charts and return base64 HTML images\n",
        "def plot_momentum(df):\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.bar(df['title'], df['momentum'], color='skyblue')\n",
        "    ax.set_title(\"Momentum (Recent View Gain)\", fontsize=14)\n",
        "    ax.set_ylabel(\"View Gain\")\n",
        "    ax.set_xlabel(\"Video Title\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "    buf.close()\n",
        "    plt.close()\n",
        "    return f\"<img src='data:image/png;base64,{img_base64}'/>\"\n",
        "\n",
        "def plot_privacy_risk_distribution(df):\n",
        "    fig, ax = plt.subplots()\n",
        "    df['privacy risk'].value_counts().plot.pie(autopct='%1.1f%%', colors=['#4CAF50','#FFC107','#F44336'], ax=ax)\n",
        "    ax.set_ylabel('')\n",
        "    ax.set_title(\"Privacy Risk Distribution\")\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "    buf.close()\n",
        "    plt.close()\n",
        "    return f\"<img src='data:image/png;base64,{img_base64}'/>\""
      ],
      "metadata": {
        "id": "A3mArD7tSkyQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio function\n",
        "def get_trending_videos(region='IN', max_results=10):\n",
        "    response = fetch_trending_videos(region, max_results)\n",
        "    df = parse_response(response)\n",
        "    chart_html = plot_momentum(df)\n",
        "    risk_html = plot_privacy_risk_distribution(df)\n",
        "    combined_html = chart_html + \"<br><br>\" + risk_html\n",
        "    return df, combined_html"
      ],
      "metadata": {
        "id": "In6DJiDFSmeK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "gr.Interface(\n",
        "    fn=get_trending_videos,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Region Code (e.g., IN, US, UK)\", value=\"IN\"),\n",
        "        gr.Slider(1, 20, value=10, step=1, label=\"Number of Trending Videos\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Dataframe(label=\"Trending YouTube Videos with Features & Privacy Risk\"),\n",
        "        gr.HTML(label=\"Visualizations: Momentum + Privacy Risk\")\n",
        "    ],\n",
        "    title=\"ðŸ“Š YouTube Trending Video Analyzer with Privacy Detection\",\n",
        "    description=\"Fetches real-time trending videos from YouTube, analyzes metadata for sentiment, momentum, and privacy risk using heuristics.\"\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "8aRjWL_HSp9q",
        "outputId": "cd6357f3-7dbe-4c51-ac0c-0982065b0d48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f87eeebab8119cf84e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f87eeebab8119cf84e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}